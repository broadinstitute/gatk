package org.broadinstitute.hellbender.tools.exome.eval;

import htsjdk.samtools.util.Locatable;
import htsjdk.variant.variantcontext.Allele;
import htsjdk.variant.variantcontext.Genotype;
import htsjdk.variant.variantcontext.GenotypeBuilder;
import htsjdk.variant.variantcontext.VariantContext;
import htsjdk.variant.variantcontext.writer.VariantContextWriter;
import htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder;
import htsjdk.variant.vcf.*;
import org.apache.commons.lang3.tuple.ImmutablePair;
import org.apache.commons.lang3.tuple.Pair;
import org.broadinstitute.barclay.argparser.Argument;
import org.broadinstitute.barclay.argparser.ArgumentCollection;
import org.broadinstitute.barclay.argparser.CommandLineProgramProperties;
import org.broadinstitute.barclay.help.DocumentedFeature;
import org.broadinstitute.hellbender.cmdline.CommandLineProgram;
import org.broadinstitute.hellbender.cmdline.StandardArgumentDefinitions;
import org.broadinstitute.hellbender.cmdline.programgroups.CopyNumberProgramGroup;
import org.broadinstitute.hellbender.exceptions.UserException;
import org.broadinstitute.hellbender.tools.exome.Target;
import org.broadinstitute.hellbender.tools.exome.TargetArgumentCollection;
import org.broadinstitute.hellbender.tools.exome.TargetCollection;
import org.broadinstitute.hellbender.tools.exome.germlinehmm.CopyNumberTriStateAllele;
import org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentCaller;
import org.broadinstitute.hellbender.tools.exome.germlinehmm.xhmm.XHMMSegmentGenotyper;
import org.broadinstitute.hellbender.utils.*;
import org.broadinstitute.hellbender.utils.hmm.segmentation.HMMPostProcessor;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.*;
import java.util.function.Function;
import java.util.stream.Collectors;
import java.util.stream.Stream;
import java.util.stream.StreamSupport;

/**
 * Tool to evaluate the output of {@link XHMMSegmentCaller}.
 *
 * <p>Example:</p>
 *
 * <pre>
 * gatk-launch --javaOptions "-Xmx4g" EvaluateCopyNumberTriStateCalls \
 *      --callsFile genotyped_segments.vcf \
 *      --truthFile genomestrip_cnv.vcf \
 *      --targets pca_filtered_targets.tsv \
 *      --output evaluation.vcf \
 *      --siteDetailsOutput evaluation-sites.tab \
 *      --sampleSummaryOutput evaluation-sample-summary.tab \
 *      --includeOverallSummaryOutputLine \
 *      --applyMultiAllelicTruthFilter \
 *      --applyMultiAllelicCalledFilter \
 *      --minimumTruthSegmentLength 4 \
 *      --minimumCalledSegmentLength 4 \
 *      --maximumTruthEventFrequency 0.05 \
 *      --maximumCalledEventFrequency 0.05 \
 *      --minimumTruthSegmentQuality 30 \
 *      --minimumCalledSegmentQuality 90
 * </pre>
 *
 * <h3>Inputs</h3>
 * <p>You must provide the following three inputs:</p>
 * <ul>
 *     <li>The <b>calls</b> file with the calls generated by {@link XHMMSegmentGenotyper} properly
 *     indexed.</li>
 *     <li>The <b>truth</b> in Genome-STRiP's VCF format, also indexed</li>.
 *     <li>and finally the <b>targets</b> file with the list of targets to consider for evaluation. It should be
 *     the same that was used for the segment discovery and genotyping.</li>
 * </ul>
 * <p>Anything less than that will result in a user error.</p>
 *
 * <h3>Outputs</h3>
 * <p>At least you need to provide a file name of the main evaluation VCF output (-O argument)</p>.
 * <p>Also you may elect to provide a sample summary file that summarizes the counts of different evaluation classes (TP, FP, FN, ...) per sample.
 * (-summary argument) or and a file to dump detail output of each evaluation (-sites argument)</p>.
 * <p>For the former you can ask the for the output to contain a row that adds up all counts across all samples (-includeOverall flag)</p>
 *
 * <h3>Filtering</h3>
 * <p>You are strongly advised to apply a few filters to the truth and calls when evaluating:</p>
 * <dl>
 *     <dt>-applyMATFilter</dt><dd>Multi allelic truth filter; sites where the truth contains samples with both deletion and duplications are not
 *     considered for evaluation</dd>
 *     <dt>-applyMACFilter</dt><dd>Multi allelic calles filter; sites where the there are deletion and duplication calls, those calls
 *      are treated as nonexistent. This may result in a false negatives but with the idea of reducing false positives.</dd>
 *     <dt>-</dt>
 * </dl>
 * @author Valentin Ruano-Rubio &lt;valentin@broadinstitute.org&gt;
 */
@CommandLineProgramProperties(
        summary = "Evaluate a set of call segments against the truth segments",
        oneLineSummary = "(Internal) Evaluate a set of germline call segments",
        programGroup = CopyNumberProgramGroup.class
)
@DocumentedFeature
public final class EvaluateCopyNumberTriStateCalls extends CommandLineProgram {

    public static final String CALLS_FILE_SHORT_NAME = "calls";
    public static final String CALLS_FILE_FULL_NAME = "callsFile";
    public static final String TRUTH_FILE_SHORT_NAME = "truth";
    public static final String TRUTH_FILE_FULL_NAME = "truthFile";
    public static final String SAMPLES_SHORT_NAME = "sample";
    public static final String SAMPLES_FULL_NAME = "sample";
    public static final String SAMPLES_LIST_SHORT_NAME = "samples";
    public static final String SAMPLES_LIST_FULL_NAME = "sampleList";
    public static final String SAMPLE_SUMMARY_OUTPUT_SHORT_NAME = "summary";
    public static final String SAMPLE_SUMMARY_OUTPUT_FULL_NAME = "sampleSummaryOutput";
    public static final String DETAIL_CALL_OUTPUT_SHORT_NAME = "sites";
    public static final String DETAIL_CALL_OUTPUT_FULL_NAME = "siteDetailsOutput";
    public static final String OVERALL_SUMMARY_LINE_SHORT_NAME = "includeOverall";
    public static final String OVERALL_SUMMARY_LINE_FULL_NAME = "includeOverallSummaryOutputLine";
    public static final String OVERALL_SUMMARY_SAMPLE_SHORT_NAME = "overallSample";
    public static final String OVERALL_SUMMARY_SAMPLE_FULL_NAME = "overallSampleName";
    public static final String REFERENCE_COPY_NUMBER_SHORT_NAME = "ploidy";
    public static final String REFERENCE_COPY_NUMBER_FULL_NAME = "referencePloidy";

    public static final String DEFAULT_OVERALL_SUMMARY_SAMPLE_NAME = "ALL";
    public static final int REFERENCE_COPY_NUMBER_DEFAULT = 2;

    private static final String GS_COPY_NUMBER_FORMAT_KEY = "CN";
    private static final String GS_COPY_NUMBER_POSTERIOR_KEY = "CNP";
    private static final String GS_COPY_NUMBER_FRACTION_KEY = "CNF";

    @ArgumentCollection
    protected TargetArgumentCollection targetArguments = new TargetArgumentCollection();

    @ArgumentCollection
    protected EvaluationFiltersArgumentCollection filterArguments = new EvaluationFiltersArgumentCollection();

    @Argument(
            doc = "File containing the called segments",
            shortName = CALLS_FILE_SHORT_NAME,
            fullName = CALLS_FILE_FULL_NAME)
    protected File callsFile;

    @Argument(
            doc = "File containing true events",
            shortName = TRUTH_FILE_SHORT_NAME,
            fullName = TRUTH_FILE_FULL_NAME,
            optional = true)
    protected File truthFile;

    @Argument(
            doc = "Output file",
            shortName = StandardArgumentDefinitions.OUTPUT_SHORT_NAME,
            fullName = StandardArgumentDefinitions.OUTPUT_LONG_NAME
    )
    protected File outputFile;

    @Argument(
            doc = "Samples to evaluate",
            shortName = SAMPLES_SHORT_NAME,
            fullName = SAMPLES_FULL_NAME,
            optional = true
    )
    protected Set<String> samples = new LinkedHashSet<>();

    @Argument(
            doc = "Samples list to evaluate",
            shortName = SAMPLES_LIST_SHORT_NAME,
            fullName  = SAMPLES_LIST_FULL_NAME,
            optional = true
    )
    protected File sampleListFile = null;

    @Argument(
            doc = "Sample summary output",
            shortName = SAMPLE_SUMMARY_OUTPUT_SHORT_NAME,
            fullName = SAMPLE_SUMMARY_OUTPUT_FULL_NAME,
            optional = true
    )
    protected File sampleSummaryOutputFile = null;

    @Argument(
            doc = "Case detail output",
            shortName = DETAIL_CALL_OUTPUT_SHORT_NAME,
            fullName = DETAIL_CALL_OUTPUT_FULL_NAME,
            optional = true
    )
    protected File caseDetailOutputFile = null;

    @Argument(
            doc = "Whether to include the overall summary line in the sample summary output file",
            shortName = OVERALL_SUMMARY_LINE_SHORT_NAME,
            fullName = OVERALL_SUMMARY_LINE_FULL_NAME,
            optional = true
    )
    protected boolean includeOverallSummaryRecord = false;

    @Argument(
            doc = "Special sample name used for the overall summary output line",
            shortName = OVERALL_SUMMARY_SAMPLE_SHORT_NAME,
            fullName = OVERALL_SUMMARY_SAMPLE_FULL_NAME,
            optional = true
    )
    protected String overallSampleSummaryRecordSampleName = DEFAULT_OVERALL_SUMMARY_SAMPLE_NAME;

    @Argument(
            doc = "Reference copy number",
            shortName = REFERENCE_COPY_NUMBER_SHORT_NAME,
            fullName = REFERENCE_COPY_NUMBER_FULL_NAME,
            optional = true
    )
    protected int truthNeutralCopyNumber = REFERENCE_COPY_NUMBER_DEFAULT;

    @Override
    protected Object doWork() {
        final TargetCollection<Target> targets = targetArguments.readTargetCollection(false);
        final VCFFileReader truthReader = openVCFReader(truthFile);
        final VCFFileReader callsReader = openVCFReader(callsFile);
        final GenotypeEvaluationRecordWriter caseWriter = openGenotypeEvaluationOutputWriter(caseDetailOutputFile);
        if (samples.isEmpty()) {
            samples = composeSetOfSamplesToEvaluate(callsReader);
        }
        final VariantContextWriter outputWriter = openVCFWriter(outputFile, samples);
        final Map<String, EvaluationSampleSummaryRecord> sampleStats = samples.stream()
                .collect(Collectors.toMap(s -> s, EvaluationSampleSummaryRecord::new));
        final List<SimpleInterval> intervals = composeListOfProcessingIntervalsFromInputs(truthReader, callsReader);
        for (final SimpleInterval interval : intervals) {
            for (final VariantEvaluationContext vc : processInterval(truthReader, callsReader, interval, targets)) {
                outputWriter.add(vc);
                outputCases(caseWriter, vc, targets);
                updateSampleStats(sampleStats, vc);
            }
        }
        truthReader.close();
        callsReader.close();
        outputWriter.close();
        closeCaseRecordWriter(caseWriter);
        writeSampleSummaryFile(sampleSummaryOutputFile, sampleStats);

        return "SUCCESS";
    }

    private void closeCaseRecordWriter(final GenotypeEvaluationRecordWriter caseWriter) {
        try {
           if (caseWriter != null) {
               caseWriter.close();
           }
        } catch (final IOException ex) {
            throw new UserException.CouldNotCreateOutputFile(caseDetailOutputFile, ex);
        }
    }

    private void outputCases(final GenotypeEvaluationRecordWriter caseWriter, final VariantEvaluationContext vc, final TargetCollection<Target> targets) {
        if (caseWriter == null) {
            return;
        }
        for (final Genotype g : vc.getGenotypes()) {
            final EvaluationClass evalClass =
                    GATKProtectedVariantContextUtils.getAttributeAsObject(g, VariantEvaluationContext.EVALUATION_CLASS_KEY,
                            EvaluationClass::parseString, null);
            if (evalClass == null) {
                continue;
            }
            final String sample = g.getSampleName();
            final SimpleInterval interval = new SimpleInterval(vc);
            final int targetCount = getTargetCount(targets, interval, g);
            final Set<String> variantFilters = vc.getFilters();
            final Genotype genotype = vc.getGenotype(sample);
            final Set<String> genotypeFilterArray = genotype.getFilters() == null ? Collections.emptySet()
                    : Stream.of(genotype.getFilters().split(VCFConstants.INFO_FIELD_ARRAY_SEPARATOR)).collect(Collectors.toSet());
            final Set<String> allFilterStrings = new LinkedHashSet<>();
            allFilterStrings.addAll(variantFilters);
            allFilterStrings.addAll(genotypeFilterArray);
            final Set<EvaluationFilter> allFilters = allFilterStrings.stream().map(EvaluationFilter::fromString).filter(Objects::nonNull).collect(Collectors.toSet());

            final GenotypeEvaluationRecord record = new GenotypeEvaluationRecord(sample, interval, targetCount, evalClass, allFilters, vc);
            try {
                caseWriter.writeRecord(record);
            } catch (final IOException ex) {
                throw new UserException.CouldNotCreateOutputFile(caseDetailOutputFile, ex);
            }
        }
    }

    private void writeSampleSummaryFile(final File outputFile, final Map<String, EvaluationSampleSummaryRecord> sampleStats) {
        if (sampleSummaryOutputFile == null) {
            return;
        }
        try (final EvaluationSampleSummaryWriter writer =
                     new EvaluationSampleSummaryWriter(outputFile, overallSampleSummaryRecordSampleName)) {
            for (final EvaluationSampleSummaryRecord record : sampleStats.values()) {
                writer.writeRecord(record);
            }
            writeOverallSummaryRecordIfApplies(writer);
        } catch (final IOException ex) {
            throw new UserException.CouldNotCreateOutputFile(outputFile, ex);
        }
    }

    private void updateSampleStats(final Map<String, EvaluationSampleSummaryRecord> sampleStats, final VariantEvaluationContext vc) {
        // ignore filtered out variants.
        if (vc.getFilters().stream().anyMatch(f -> !VCFConstants.PASSES_FILTERS_v4.equals(f))) {
            return;
        }
        for (final Genotype genotype : vc.getGenotypes()) {
            final Set<String> filters = genotype.getFilters() == null ? Collections.emptySet()
                    : Stream.of(genotype.getFilters().split(VCFConstants.INFO_FIELD_ARRAY_SEPARATOR)).collect(Collectors.toSet());
            if (filters.stream().anyMatch(s -> !s.equals(VCFConstants.PASSES_FILTERS_v4))) {
                continue;
            }
            final String sample = genotype.getSampleName();
            final String evalClassString = GATKProtectedVariantContextUtils.getAttributeAsString(genotype, VariantEvaluationContext.EVALUATION_CLASS_KEY, null);
            if (evalClassString != null) {
                final EvaluationClass evalClass = EvaluationClass.parseString(evalClassString);
                sampleStats.get(sample).increase(evalClass);
            }
        }
    }

    private VariantContextWriter openVCFWriter(final File outputFile, final Set<String> samples) {
        final VariantContextWriterBuilder builder = new VariantContextWriterBuilder();
        builder.setOutputFile(outputFile);
        builder.clearOptions();
        final VariantContextWriter result = builder.build();
        final VCFHeader header = new VCFHeader(Collections.emptySet(), samples);
        CopyNumberTriStateAllele.addHeaderLinesTo(header);
        EvaluationClass.addHeaderLinesTo(header);

        // Format annotations.
        header.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_KEY, 1, VCFHeaderLineType.Character, "Called genotype"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.CALL_QUALITY_KEY, 1, VCFHeaderLineType.Float, "Quality of the call"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.CALLED_SEGMENTS_COUNT_KEY, 1, VCFHeaderLineType.Integer, "Number of called segments that overlap with the truth"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.CALLED_ALLELE_COUNTS_KEY, VCFHeaderLineCount.G, VCFHeaderLineType.Integer, "Called allele count for mixed calls"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.TRUTH_COPY_FRACTION_KEY, 1, VCFHeaderLineType.Float, "Truth copy fraction estimated"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.TRUTH_QUALITY_KEY, 1, VCFHeaderLineType.Float, "Truth call quality"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.EVALUATION_CLASS_KEY, 1, VCFHeaderLineType.Character, "The evaluation class for the call or lack of call. It the values of the header key '" + EvaluationClass.VCF_HEADER_KEY + "'"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.TRUTH_GENOTYPE_KEY, 1, VCFHeaderLineType.Character, "The truth genotype"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.CALLED_TARGET_COUNT_KEY, 1, VCFHeaderLineType.Integer, "Number of targets covered by called segments"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VariantEvaluationContext.CALL_QUALITY_KEY, 1, VCFHeaderLineType.Float, "1 - The probability of th event in Phred scale (the maximum if ther are more than one segment"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_QUALITY_KEY, 1, VCFHeaderLineType.Integer, "The quality of the call (the maximum if there are more than one segment"));
        header.addMetaDataLine(new VCFFormatHeaderLine(VCFConstants.GENOTYPE_FILTER_KEY, VCFHeaderLineCount.UNBOUNDED, VCFHeaderLineType.Character, "Genotype filters"));

        // Info annotations.
        header.addMetaDataLine(new VCFInfoHeaderLine(VariantEvaluationContext.TRUTH_ALLELE_FREQUENCY_KEY, VCFHeaderLineCount.A, VCFHeaderLineType.Float, "The frequency of the alternative alleles in the truth callset"));
        header.addMetaDataLine(new VCFInfoHeaderLine(VariantEvaluationContext.TRUTH_ALLELE_NUMBER_KEY, 1, VCFHeaderLineType.Integer, "Total number of called alleles in the truth callset"));
        header.addMetaDataLine(new VCFInfoHeaderLine(VariantEvaluationContext.CALLS_ALLELE_FREQUENCY_KEY, VCFHeaderLineCount.A, VCFHeaderLineType.Float, "The frequency of the alternative alleles in the actual callset"));
        header.addMetaDataLine(new VCFInfoHeaderLine(VariantEvaluationContext.CALLS_ALLELE_NUMBER_KEY, 1, VCFHeaderLineType.Integer, "Total number of called alleles in the actual callset"));
        header.addMetaDataLine(new VCFInfoHeaderLine(VariantEvaluationContext.TRUTH_TARGET_COUNT_KEY, 1, VCFHeaderLineType.Integer, "Number of targets overlapped by this variant"));
        header.addMetaDataLine(new VCFInfoHeaderLine(VCFConstants.END_KEY, 1, VCFHeaderLineType.Integer, "Stop position for the variant"));

        // Filter annotations.
        for (final EvaluationFilter filter : EvaluationFilter.values()) {
            header.addMetaDataLine(new VCFFilterHeaderLine(filter.name(), filter.description));
            header.addMetaDataLine(new VCFFilterHeaderLine(filter.acronym, filter.description));
        }
        header.addMetaDataLine(new VCFFilterHeaderLine(EvaluationFilter.PASS, "Indicates that it passes all filters"));
        result.writeHeader(header);
        return result;
    }

    /**
     * Processes a cluster of truth and called variants that may overlap over a genome region.
     * <p>
     * It returns the list of {@link VariantEvaluationContext} instances to be output for the given interval. These
     * are already sorted by coordinates.
     * </p>
     * @param truthReader reader to the truth variants.
     * @param callsReader reader to the called variants.
     * @param interval the interval to analyze.
     * @return never {@code null}.
     */
    private List<VariantEvaluationContext> processInterval(final VCFFileReader truthReader, final VCFFileReader callsReader,
                                                 final SimpleInterval interval, final TargetCollection<Target> targets) {
        final List<VariantContext> truthVariants = variantQueryToList(truthReader, interval);
        final List<VariantContext> callsVariants = variantQueryToList(callsReader, interval);
        final List<VariantEvaluationContext> evaluatedVariants = new ArrayList<>(truthVariants.size() + callsVariants.size());
        for (final VariantContext truth : truthVariants) {
            // skip truth that does not overlap a single target.
            if (targets.targetCount(truth) == 0) {
                continue;
            }
            final List<VariantContext> overlappingCalls = callsVariants.stream()
                    .filter(vc -> IntervalUtils.overlaps(truth, vc))
                    .collect(Collectors.toList());
            evaluatedVariants.add(composeTruthOverlappingVariantContext(truth, overlappingCalls, targets));
        }
        for (final VariantContext call : callsVariants) {
            // skip call that does not overlap a single target (the user might want to call on a smaller set of targets)
            if (targets.targetCount(call) == 0) {
                continue;
            }
            final List<VariantContext> overlappingTruth = truthVariants.stream()
                    .filter(vc -> IntervalUtils.overlaps(call, vc))
                    .collect(Collectors.toList());
            if (overlappingTruth.isEmpty()) {
                evaluatedVariants.add(composeNonTruthOverlappingVariantContext(call, targets)) ;
            }
        }
        return evaluatedVariants.stream()
                .sorted(IntervalUtils.LEXICOGRAPHICAL_ORDER_COMPARATOR)
                .map(this::applyVariantContextFilters)
                .collect(Collectors.toList());
    }

    /**
     * Augments the variant context to variant-context level filters if these apply.
     * @param vec the variant context to augment.
     * @return never null, potentially a new variant context with the same contents as the input but with changes
     *  in the filter set.
     */
    private VariantEvaluationContext applyVariantContextFilters(final VariantEvaluationContext vec) {
        final Set<EvaluationFilter> filters = new LinkedHashSet<>();
        if (vec.getTruthAlleleNumber() > 0 && filterArguments.maximumTruthEventFrequency < 1.0 - vec.getTruthAlleleFrequency(CopyNumberTriStateAllele.REF)) {
            filters.add(EvaluationFilter.CommonEvent);
        }
        if (vec.getTruthAlleleNumber() == 0 && filterArguments.maximumCalledEventFrequency < 1.0 - vec.getCallsAlleleFrequency(CopyNumberTriStateAllele.REF)) {
            filters.add(EvaluationFilter.CommonEvent);
        }
        if (vec.getTruthAlleleNumber() > 0 && filterArguments.minimumTruthSegmentLength > vec.getTargetCount()) {
            filters.add(EvaluationFilter.ShortEvent);
        }
        if (vec.getTruthAlleleNumber() == 0 && filterArguments.minimumCalledSegmentLength > vec.getTargetCount()) {
            filters.add(EvaluationFilter.ShortEvent);
        }
        if (filterArguments.applyMultiAllelicTruthFilter && vec.getTruthAlleleFrequency(CopyNumberTriStateAllele.DEL) > 0 &&
                vec.getTruthAlleleFrequency(CopyNumberTriStateAllele.DUP) > 0) {
            filters.add(EvaluationFilter.MultiAllelicTruth);
        }
        if (filterArguments.applyMultiAllelicCalledFilter && vec.getCallsAlleleFrequency(CopyNumberTriStateAllele.DEL) > 0 &&
                vec.getCallsAlleleFrequency(CopyNumberTriStateAllele.DUP) > 0) {
            filters.add(EvaluationFilter.MultiAllelicCalls);
        }
        final Set<String> filterStrings = filters.isEmpty() ? Collections.singleton(EvaluationFilter.PASS) :
                filters.stream().map(Enum<EvaluationFilter>::name).collect(Collectors.toSet());

        final VariantEvaluationContextBuilder builder = new VariantEvaluationContextBuilder(vec);
        builder.filters(filterStrings);
        return builder.make();
    }

    /**
     * Compose a {@link VariantEvaluationContext} that does not overlap any truth record.
     * @param call the variant-context representing the call.
     * @param targets target collection under analysis.
     * @return never {@code null}.
     */
    private VariantEvaluationContext composeNonTruthOverlappingVariantContext(final VariantContext call, final TargetCollection<Target> targets) {
        return composeEvaluationVariantContext(call, call.getAlleles(), s -> composeNonTruthOverlappingGenotype(call, call.getGenotype(s)),
                targets, null, Collections.singletonList(call));
    }

    private Genotype composeNonTruthOverlappingGenotype(final VariantContext enclosingContext, final Genotype genotype) {
        final GenotypeBuilder builder = new GenotypeBuilder(genotype.getSampleName());
        if (genotype.isCalled()) {
            GATKProtectedVariantContextUtils.setGenotypeQualityFromPLs(builder, genotype);
            final int[] PL = genotype.getPL();
            final int callAlleleIndex = GATKProtectedMathUtils.minIndex(PL);
            final double quality = callQuality(genotype);
            builder.alleles(Collections.singletonList(enclosingContext.getAlleles().get(callAlleleIndex)));
            builder.attribute(VariantEvaluationContext.CALL_QUALITY_KEY, quality);
            final boolean discovered = XHMMSegmentGenotyper.DISCOVERY_TRUE.equals(
                    GATKProtectedVariantContextUtils.getAttributeAsString(genotype, XHMMSegmentGenotyper.DISCOVERY_KEY,
                            XHMMSegmentGenotyper.DISCOVERY_FALSE));
            if (callAlleleIndex != 0 && discovered) {
                builder.attribute(VariantEvaluationContext.EVALUATION_CLASS_KEY, EvaluationClass.UNKNOWN_POSITIVE.acronym);
            }
            if (quality < filterArguments.minimumCalledSegmentQuality) {
                builder.filter(EvaluationFilter.LowQuality.acronym);
            } else {
                builder.filter(EvaluationFilter.PASS);
            }
        } else { /* assume it is REF */
            /* TODO this is a hack to make Andrey's CODEX vcf work; and in general, VCFs that only include discovered
             * variants and NO_CALL (".") on other samples. The idea is to force the evaluation tool to take it call
             * as REF on all other samples. Otherwise, the effective allele frequency of the variant will be erroneously
             * high and will be filtered. */
            builder.alleles(Collections.singletonList(CopyNumberTriStateAllele.REF));
            builder.attribute(VariantEvaluationContext.CALL_QUALITY_KEY, 100000);
            builder.filter(EvaluationFilter.PASS);
        }
        return builder.make();
    }

    private double callQuality(final Genotype genotype) {
        return GATKProtectedMathUtils.secondSmallestMinusSmallest(genotype.getPL(), 0);
    }

    private VariantEvaluationContext composeEvaluationVariantContext(final VariantContext location, final List<Allele> alleles,
                                                                     final Function<String, Genotype> genotypeComposer,
                                                                     final TargetCollection<Target> targets,
                                                                     final VariantContext truth, final List<VariantContext> calls) {
        final VariantEvaluationContextBuilder builder = new VariantEvaluationContextBuilder();
        builder.id(location.getID());
        builder.loc(location.getContig(), location.getStart(), location.getEnd());
        builder.attribute(VCFConstants.END_KEY, location.getEnd());
        builder.alleles(alleles);
        builder.genotypes(samples.stream()
            .map(genotypeComposer)
            .collect(Collectors.toList()));
        builder.attribute(XHMMSegmentGenotyper.NUMBER_OF_TARGETS_KEY, targets.targetCount(location));
        builder.evidence(truth, calls);
        return builder.make();
    }

    private VariantEvaluationContext composeTruthOverlappingVariantContext(final VariantContext truth, final List<VariantContext> calls,
                                                                           final TargetCollection<Target> targets) {
        return composeEvaluationVariantContext(truth, CopyNumberTriStateAllele.PLAIN_ALL_ALLELES, s -> buildAndAnnotateTruthOverlappingGenotype(s, truth, calls, targets),
                targets, truth, calls);
    }

    private Genotype buildAndAnnotateTruthOverlappingGenotype(final String sample, final VariantContext truth, final List<VariantContext> calls,
                                                              final TargetCollection<Target> targets) {
        final Genotype truthGenotype = truth.getGenotype(sample);
        // if there is no truth genotype for that sample, we output the "empty" genotype.
        if (truthGenotype == null) {
            return GenotypeBuilder.create(sample, Collections.emptyList());
        }
        final int truthCopyNumber = GATKProtectedVariantContextUtils.getAttributeAsInt(truthGenotype,
                GS_COPY_NUMBER_FORMAT_KEY, truthNeutralCopyNumber);
        final CopyNumberTriStateAllele truthAllele = copyNumberToTrueAllele(truthCopyNumber);

        final List<Pair<VariantContext, Genotype>> allCalls = calls.stream()
                .map(vc -> new ImmutablePair<>(vc, vc.getGenotype(sample)))
                .filter(pair -> pair.getRight() != null)
                .filter(pair -> GATKProtectedVariantContextUtils.getAttributeAsString(pair.getRight(), XHMMSegmentGenotyper.DISCOVERY_KEY,
                        XHMMSegmentGenotyper.DISCOVERY_FALSE).equals(XHMMSegmentGenotyper.DISCOVERY_TRUE))
                .collect(Collectors.toList());

        final List<Pair<VariantContext, Genotype>> qualifiedCalls = composeQualifyingCallsList(targets, allCalls);

        return buildAndAnnotateTruthOverlappingGenotype(sample, targets, truthGenotype, truthCopyNumber,
                    truthAllele, qualifiedCalls);
    }

    /**
     * Return the number of targets spanned by a variant context.
     *
     * If the genotype has the target count attribute, we use that; otherwise, we infer it from the
     * target list.
     *
     * @param targets master target list
     * @param interval the interval where the variant belongs
     * @param g {@link Genotype} of the variant
     * @return integer count of spanning targets
     */
    private int getTargetCount(final TargetCollection<Target> targets, final Locatable interval, final Genotype g) {
        return GATKProtectedVariantContextUtils.getAttributeAsInt(g,
                HMMPostProcessor.NUMBER_OF_SAMPLE_SPECIFIC_TARGETS_KEY,
                targets.targetCount(interval));
    }

    /**
     * Reduces a list of calls to the ones that pass filters.
     * @param targets collection of targets under analysis.
     * @param calls calls to filter.
     * @return never {@code null}, but perhaps
     */
    private List<Pair<VariantContext, Genotype>> composeQualifyingCallsList(final TargetCollection<Target> targets,
                                                                            final List<Pair<VariantContext, Genotype>> calls) {
        return calls.stream()
                // Filter vc/gt with no concrete call or that the call is the reference.
                .filter(pair -> pair.getRight().getAlleles().stream().anyMatch(a -> a.isCalled() && a.isNonReference()))
                // Filter vc/gt with low call quality (SQ).
                .filter(pair -> callQuality(pair.getRight()) >= filterArguments.minimumCalledSegmentQuality)
                // Filter vc/gt with small segments (small number of targets). If the call genotype has sample number
                // of targets attribute, we use that; otherwise, we get the target count from the target list
                .filter(pair -> getTargetCount(targets, pair.getLeft(), pair.getRight()) >= filterArguments.minimumCalledSegmentLength)
                // Filter vc/gt with that seem to be too common.
                // or if it is multi-allelic when applies.
                .filter(pair -> {
                    final double[] calledAF = GATKProtectedVariantContextUtils.getAttributeAsDoubleArray(pair.getLeft(),
                            VCFConstants.ALLELE_FREQUENCY_KEY, () -> new double[pair.getLeft().getAlleles().size() - 1],
                            0.0);
                    final double nonRefAF = MathUtils.sum(calledAF);
                    return nonRefAF <= filterArguments.maximumCalledEventFrequency
                            && !(filterArguments.applyMultiAllelicCalledFilter && calledAF.length > 1 && calledAF[0] > 0 && calledAF[1] > 0);
                })
                .collect(Collectors.toList());
    }

    private Genotype buildAndAnnotateTruthOverlappingGenotype(final String sample,
                                                              final TargetCollection<Target> targets,
                                                              final Genotype truthGenotype,
                                                              final int truthCopyNumber,
                                                              final CopyNumberTriStateAllele truthAllele,
                                                              final List<Pair<VariantContext, Genotype>> calls) {
        final Set<CopyNumberTriStateAllele> calledAlleles = calls.stream()
                .map(pair -> CopyNumberTriStateAllele.valueOf(pair.getRight().getAllele(0)))
                .collect(Collectors.toSet());

        final Allele calledAllele = calledAlleles.size() == 1 ? calledAlleles.iterator().next() : Allele.NO_CALL;
        final GenotypeBuilder builder = new GenotypeBuilder(sample);

        // Set the call allele.
        builder.alleles(Collections.singletonList(calledAllele));

        // Set the truth allele.
        builder.attribute(VariantEvaluationContext.TRUTH_GENOTYPE_KEY, CopyNumberTriStateAllele.ALL_ALLELES.indexOf(truthAllele));

        // Annotate the genotype with the number of calls.
        builder.attribute(VariantEvaluationContext.CALLED_SEGMENTS_COUNT_KEY, calls.size());

        // When there is more than one qualified type of event we indicate how many.
        builder.attribute(VariantEvaluationContext.CALLED_ALLELE_COUNTS_KEY,
                CopyNumberTriStateAllele.ALL_ALLELES.stream()
                        .mapToInt(allele -> (int) calls.stream()
                                .filter(pair -> pair.getRight().getAllele(0).equals(allele, true))
                                .count())
                        .toArray());

        // Calculate the length in targets of the call as the sum across all calls.
        builder.attribute(VariantEvaluationContext.CALLED_TARGET_COUNT_KEY,
                calls.stream().mapToInt(pair -> getTargetCount(targets, pair.getLeft(), pair.getRight()))
                        .sum());

        // Calculate call quality-- if there is more than one overlapping call we take the maximum qual one.
        builder.attribute(VariantEvaluationContext.CALL_QUALITY_KEY,
                calls.stream().mapToDouble(pair -> GATKProtectedVariantContextUtils.calculateGenotypeQualityFromPLs(pair.getRight())).max().orElse(0.0));

        // Calculate the truth copy fraction.
        builder.attribute(VariantEvaluationContext.TRUTH_COPY_FRACTION_KEY,
                truthGenotype.getExtendedAttribute(GS_COPY_NUMBER_FRACTION_KEY));

        // Calculate the truth call quality.
        final double truthQuality = calculateTruthQuality(truthGenotype, truthCopyNumber);
        builder.attribute(VariantEvaluationContext.TRUTH_QUALITY_KEY, truthQuality);

        // Set genotype filters:
        final boolean truthPassQualityMinimum = truthQuality >= filterArguments.minimumTruthSegmentQuality;
        builder.filter(truthPassQualityMinimum ? EvaluationFilter.PASS
                    : EvaluationFilter.LowQuality.acronym);

        // Calculate the evaluation class (TP, FN, etc.). Only if there is actually either a truth or a call that is not ref.
        if (calledAlleles.contains(CopyNumberTriStateAllele.DEL) || calledAlleles.contains(CopyNumberTriStateAllele.DUP) || truthAllele != CopyNumberTriStateAllele.REF) {
            final EvaluationClass evaluationClass;
            if (calledAlleles.isEmpty() || (calledAlleles.size() == 1 && calledAlleles.contains(CopyNumberTriStateAllele.REF))) {
                evaluationClass = EvaluationClass.FALSE_NEGATIVE;
            } else if (calledAlleles.size() == 1) {
                evaluationClass = calledAlleles.contains(truthAllele) ? EvaluationClass.TRUE_POSITIVE :
                        truthAllele == CopyNumberTriStateAllele.REF ? EvaluationClass.FALSE_POSITIVE :
                              /* else */ EvaluationClass.DISCORDANT_POSITIVE;
            } else {
                evaluationClass = truthAllele == CopyNumberTriStateAllele.REF ? EvaluationClass.FALSE_POSITIVE
                        : EvaluationClass.MIXED_POSITIVE;
            }
            builder.attribute(VariantEvaluationContext.EVALUATION_CLASS_KEY, evaluationClass.acronym);
        }
        return builder.make();
    }

    /**
     * Calculate the truth call quality when we collapse copy-numbers into deletion, neutral (ref) and duplication.
     *
     * @param truthGenotype the genotype containing the posteriors log10 to use for the calculation.
     * @param truthCopyNumber the truth call copy number.
     * @return never {@code null}, a Phred scaled quality score 0 or greater.
     */
    private double calculateTruthQuality(final Genotype truthGenotype, final int truthCopyNumber) {
        final double[] truthPosteriors = GATKProtectedVariantContextUtils.getAttributeAsDoubleArray(truthGenotype,
                GS_COPY_NUMBER_POSTERIOR_KEY, () -> new double[truthCopyNumber + 1],
                Double.NEGATIVE_INFINITY);
        final double totalLog10Prob = MathUtils.log10SumLog10(truthPosteriors);
        final double delLog10Prob = MathUtils.log10SumLog10(truthPosteriors, 0, Math.min(truthNeutralCopyNumber, truthPosteriors.length)) - totalLog10Prob;
        final double neutralLog10Prob = truthNeutralCopyNumber >= truthPosteriors.length ? Double.NEGATIVE_INFINITY : truthPosteriors[truthNeutralCopyNumber] - totalLog10Prob;
        final double dupLog10Prob = truthNeutralCopyNumber + 1 >= truthPosteriors.length ? Double.NEGATIVE_INFINITY
                : MathUtils.log10SumLog10(truthPosteriors, truthNeutralCopyNumber + 1, truthPosteriors.length) - totalLog10Prob;
        if (truthCopyNumber < truthNeutralCopyNumber) {
            return -10.0 * MathUtils.approximateLog10SumLog10(neutralLog10Prob, dupLog10Prob);
        } else if (truthCopyNumber > truthNeutralCopyNumber) {
            return -10.0 * MathUtils.approximateLog10SumLog10(neutralLog10Prob, delLog10Prob);
        } else {
            return -10.0 * MathUtils.approximateLog10SumLog10(delLog10Prob, dupLog10Prob);
        }
    }

    private CopyNumberTriStateAllele copyNumberToTrueAllele(final int cn) {
        if (cn == truthNeutralCopyNumber) {
            return CopyNumberTriStateAllele.REF;
        } else if (cn < truthNeutralCopyNumber) {
            return CopyNumberTriStateAllele.DEL;
        } else {
            return CopyNumberTriStateAllele.DUP;
        }
    }

    /**
     * Collects all the variants in an interval on a list strictly sorted by the start position and the by the end
     *   position.
     *
     * @param reader the variant source reader.
     * @param interval the query interval.
     * @return never {@code null}, potentially immutably
     */
    private List<VariantContext> variantQueryToList(final VCFFileReader reader, final Locatable interval) {
        return StreamSupport.stream(Spliterators.spliteratorUnknownSize(reader.query(interval.getContig(),
                interval.getStart(), interval.getEnd()), Spliterator.NONNULL),false)
                .sorted(IntervalUtils.LEXICOGRAPHICAL_ORDER_COMPARATOR)
                .collect(Collectors.toList());
    }

    private List<SimpleInterval> composeListOfProcessingIntervalsFromInputs(final VCFFileReader truthReader,
                                                                            final VCFFileReader callsReader) {
        final Set<SimpleInterval> resultSet = new HashSet<>();
        for (final VariantContext vc : truthReader) {
            resultSet.add(new SimpleInterval(vc));
        }
        for (final VariantContext vc : callsReader) {
            resultSet.add(new SimpleInterval(vc));
        }
        if (resultSet.isEmpty()) {
            return Collections.emptyList();
        }
        final List<SimpleInterval> individualIntervals = new ArrayList<>(resultSet);
        Collections.sort(individualIntervals, IntervalUtils.LEXICOGRAPHICAL_ORDER_COMPARATOR);
        final List<SimpleInterval> result = new ArrayList<>(individualIntervals.size());
        // The buffer will contain intervals that may still overlap with
        // further intervals in individual-intervals.
        final LinkedList<SimpleInterval> overlappingBuffer = new LinkedList<>();
        overlappingBuffer.add(individualIntervals.get(0));
        for (final SimpleInterval interval : individualIntervals) {
            overlappingBuffer.add(interval);
            final boolean overlaps = overlappingBuffer.getFirst().overlaps(overlappingBuffer.getLast());
            if (overlaps) {
                final SimpleInterval merged = IntervalUtils.getSpanningInterval(overlappingBuffer);
                overlappingBuffer.clear();
                overlappingBuffer.add(merged);
            } else {
                result.add(overlappingBuffer.removeFirst());
            }
        }
        // Add the remaining contents of the buffer.
        result.addAll(overlappingBuffer);
        return result;
    }

    private VCFFileReader openVCFReader(final File file) {
        try {
            return new VCFFileReader(file, true);
        } catch (final Exception ex) {
            throw new UserException.CouldNotReadInputFile(file, ex.getMessage(), ex);
        }
    }

    private void writeOverallSummaryRecordIfApplies(final EvaluationSampleSummaryWriter sampleSummaryOutputWriter) {
        if (includeOverallSummaryRecord) {
            if (sampleSummaryOutputWriter == null) {
                logger.warn("The overall sample summary record has been requested but a sample summary " +
                        "output file was not provided");
            } else {
                try {
                    sampleSummaryOutputWriter.writeOverallRecord();
                } catch (final IOException ex) {
                    throw new UserException.CouldNotCreateOutputFile(sampleSummaryOutputFile, ex);
                }
            }
        }
    }

    private GenotypeEvaluationRecordWriter openGenotypeEvaluationOutputWriter(final File outputFile) {
        if (outputFile == null) {
            return null;
        } else {
            try {
                return new GenotypeEvaluationRecordWriter(caseDetailOutputFile);
            } catch (final IOException ex) {
                throw new UserException.CouldNotCreateOutputFile(sampleSummaryOutputFile, ex);
            }
        }
    }

    private Set<String> composeSetOfSamplesToEvaluate(final VCFFileReader calls) {
        final List<String> sampleList = composeSampleFileList();
        if (samples.isEmpty() && sampleList.isEmpty()) {
            return composeSetOfSamplesFromInputs(calls);
        } else {
            final Set<String> result = new LinkedHashSet<>(sampleList.size() + samples.size());
            result.addAll(samples);
            result.addAll(sampleList);
            return result;
        }
    }

    private List<String> composeSampleFileList() {
        if (sampleListFile == null) {
            return Collections.emptyList();
        } else {
            try (final BufferedReader reader = new BufferedReader(new FileReader(sampleListFile))) {
                return reader.lines().collect(Collectors.toList());
            } catch (final IOException ex) {
                throw new UserException.CouldNotReadInputFile(sampleListFile, ex);
            }
        }
    }

    private Set<String> composeSetOfSamplesFromInputs(final VCFFileReader calls) {
        final LinkedHashSet<String> result = new LinkedHashSet<>();
        result.addAll(extractSampleNamesFromVCFFile(calls));
        return result;
    }

    private List<String> extractSampleNamesFromVCFFile(final VCFFileReader reader) {
        return reader.getFileHeader().getSampleNamesInOrder();
    }
}

