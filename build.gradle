//Note: this section 'buildscript` is only for the dependencies of the buildscript itself.
// See the second 'repositories' section below for the actual dependencies of GATK itself
buildscript {
    repositories {
        mavenCentral()
        jcenter() // for shadow plugin
     }


}

plugins {
    id "java"
    id "application"
    id 'maven'
    id 'signing'
    id "jacoco"
    id "cpp"
    id "de.undercouch.download" version "2.1.0" //used for downloading GSA lib
    id "com.github.johnrengelman.shadow" version "1.2.3"
    id "com.github.kt3k.coveralls" version "2.6.3"
    id "com.github.ben-manes.versions" version "0.12.0" //used for identifying dependencies that need updating

}

import com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar
import de.undercouch.gradle.tasks.download.Download
import org.gradle.internal.os.OperatingSystem


mainClassName = "org.broadinstitute.hellbender.Main"

//Note: the test suite must use the same defaults. If you change system properties in this list you must also update the one in the test task
applicationDefaultJvmArgs = ["-Dsamjdk.use_async_io_samtools=true", "-Dsamjdk.use_async_io_tribble=false", "-Dsamjdk.intel_deflater_so_path=build/libIntelDeflater.so", "-Dsamjdk.compression_level=1"]

//Delete the windows script - we never test on Windows so let's not pretend it works
startScripts {
    doLast {
        delete windowsScript
    }
}

task downloadGsaLibFile(type: Download) {
    src 'http://cran.r-project.org/src/contrib/gsalib_2.1.tar.gz'
    dest "src/main/resources/org/broadinstitute/hellbender/utils/R/gsalib.tar.gz"
    overwrite false
}


repositories {
    mavenCentral()
    jcenter()

    maven {
        url "https://artifactory.broadinstitute.org/artifactory/libs-snapshot/" //for htsjdk snapshots
    }
}

configurations.all {
    resolutionStrategy {
        force 'com.google.http-client:google-http-client:1.21.0'
        // the snapshot folder contains a dev version of guava, we don't want to use that.
        force 'com.google.guava:guava:18.0'
    }
    all*.exclude group: 'org.slf4j', module: 'slf4j-jdk14' //exclude this to prevent slf4j complaining about to many slf4j bindings
    all*.exclude group: 'com.google.guava', module: 'guava-jdk5'
}

jacocoTestReport {
    dependsOn test
    group = "Reporting"
    description = "Generate Jacoco coverage reports after running tests."
    additionalSourceDirs = files(sourceSets.main.allJava.srcDirs)

    reports {
        xml.enabled = true // coveralls plugin depends on xml format report
        html.enabled = true
    }
}

jacoco {
    toolVersion = "0.7.5.201505241946"
}

//NOTE: we ignore contracts for now
compileJava {
  options.compilerArgs = ['-proc:none', '-Xlint:all','-Werror','-Xdiags:verbose']
}
compileTestJava {
  options.compilerArgs = ['-proc:none', '-Xlint:all','-Werror','-Xdiags:verbose']
}

task gcovTestReport(type: Exec){
    dependsOn test
    group = "Reporting"
    description = "Generate gcov C code coverage reports after running tests."

    String reportDir = "$buildDir/reports/gcov"
    mkdir(reportDir)

    commandLine "gcovr",  "--root=.", "-s", "--html", "--html-details", "--output=$reportDir/index.html"
}

dependencies {
    compile 'com.google.guava:guava:18.0'
    compile 'com.github.samtools:htsjdk:2.2.2'
    compile 'com.google.cloud.genomics:google-genomics-dataflow:v1beta2-0.15'
    compile 'com.google.cloud.genomics:gatk-tools-java:1.1'
    compile 'org.apache.logging.log4j:log4j-api:2.3'
    compile 'org.apache.logging.log4j:log4j-core:2.3'
    compile 'org.apache.commons:commons-lang3:3.4'
    compile 'org.apache.commons:commons-math3:3.5'
    compile 'org.apache.commons:commons-collections4:4.0'
    compile 'org.apache.commons:commons-vfs2:2.0'
    compile 'commons-io:commons-io:2.4'
    compile 'org.reflections:reflections:0.9.10'
    compile 'net.sf.jopt-simple:jopt-simple:5.0-beta-1'
    compile 'com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:0.4.150727'
    compile 'it.unimi.dsi:fastutil:7.0.6'
    compile 'com.google.apis:google-api-services-genomics:v1beta2-rev56-1.20.0'
    compile 'com.google.cloud.genomics:google-genomics-utils:v1beta2-0.30'

    compile 'org.bdgenomics.bdg-formats:bdg-formats:0.5.0'
    compile('org.bdgenomics.adam:adam-core_2.10:0.18.0') {
        exclude group: 'org.slf4j'
        exclude group: 'org.apache.hadoop'
        exclude group: 'org.scala-lang'
        exclude module: 'kryo'
        exclude module: 'hadoop-bam'
    }

    compile 'org.jgrapht:jgrapht-core:0.9.1'
    compile 'org.testng:testng:6.9.6' //compile instead of testCompile because it is needed for test infrastructure that needs to be packaged
    compile 'org.apache.hadoop:hadoop-minicluster:2.7.1' //the version of minicluster should match the version of hadoop

    compile('org.seqdoop:hadoop-bam:7.4.0') {
        exclude group: 'org.apache.hadoop'
        exclude module: 'htsjdk'
    }
    compile('org.apache.hadoop:hadoop-client:2.7.1') // should be a 'provided' dependency
    compile('com.github.jsr203hadoop:jsr203hadoop:1.0.1')

    compile('org.apache.spark:spark-core_2.10:1.5.0') {
        // JUL is used by Google Dataflow as the backend logger, so exclude jul-to-slf4j to avoid a loop
        exclude module: 'jul-to-slf4j'
        exclude module: 'javax.servlet'
        exclude module: 'servlet-api'
    }

    compile('de.javakaffee:kryo-serializers:0.26') {
        exclude module: 'kryo' // use Spark's version
    }

    //needed for DataflowAssert
    testCompile 'org.hamcrest:hamcrest-all:1.3'
    testCompile 'junit:junit:4.12'
    testCompile "org.mockito:mockito-core:1.10.19"
}

def findJarByName(Configuration config, String name) {
    config.filter { it.name.startsWith(name)}.singleFile
}

task extractIntelDeflater(type: Copy) {
    def htsjdkJar = { findJarByName(configurations.compile, 'htsjdk') }
    from {
        zipTree( htsjdkJar ).matching{ include 'lib/jni/libIntelDeflater.so'}.singleFile
    }
    into 'build/libIntelDeflater.so'
}


sourceCompatibility = 1.8
targetCompatibility = 1.8

def String deriveVersion(){
    def stdout = new ByteArrayOutputStream()
    try {
        logger.info("path is $System.env.PATH")
        exec {
            commandLine "git", "describe", "--always"
            standardOutput = stdout;

            ignoreExitValue = true
        }
    } catch (GradleException e) {
        logger.error("Couldn't determine version.  " + e.getMessage())
    }
    return stdout.size() > 0 ? stdout.toString().trim() : "version-unknown"
}
final SNAPSHOT = "-SNAPSHOT"
version = deriveVersion() + SNAPSHOT  //all builds are snapshot builds until we decide that there is something we want to keep
boolean isRelease = ! version.endsWith(SNAPSHOT)
logger.info("build for version:" + version)
group = 'org.broadinstitute'


jar {
    manifest {
        attributes 'Implementation-Title': 'Hellbender-tools',
                'Implementation-Version': version,
                'Main-Class': 'org.broadinstitute.hellbender.Main'
    }
}


test {
    outputs.upToDateWhen { false }  //tests will never be "up to date" so you can always rerun them
    String CI = "$System.env.CI"
    String CLOUD = "$System.env.CLOUD"
    String SPARK = "$System.env.SPARK"
    useTestNG{
        if (CLOUD =="mandatory") {
            // run only the cloud tests
            includeGroups 'cloud', 'bucket'
        } else if (CLOUD == "todo") {
            // run only the in-development cloud tests
            includeGroups 'cloud_todo', 'bucket_todo'
        } else if (CLOUD == "together") {
            // run both local tests and mandatory cloud tests, together.
            // This is good when e.g. you are done for the day and want to run tests on your machine overnight.
            excludeGroups 'cloud_todo', 'bucket_todo'
        } else {
            // run only the local tests
            excludeGroups 'cloud', 'bucket', 'cloud_todo', 'bucket_todo'
        }
        if (SPARK == "false") {
            // exclude Spark tests
            excludeGroups 'spark'
        }
    }

    systemProperty "samjdk.use_async_io_samtools", "true"
    systemProperty "samjdk.use_async_io_tribble", "false"
    systemProperty "samjdk.intel_deflater_so_path", "build/libIntelDeflater.so"
    systemProperty "samjdk.compression_level", "1"
    systemProperty "gatk.spark.debug", System.getProperty("gatk.spark.debug")

    // set heap size for the test JVM(s)
    minHeapSize = "1G"
    maxHeapSize = "2G"

    if (CI == "true" && CLOUD == "false" ) {
        int count = 0
        // listen to events in the test execution lifecycle
        testLogging {
            events "skipped", "failed"
            exceptionFormat = "full"
        }

        beforeTest { descriptor ->
            count++
            if( count % 10000 == 0) {
                logger.lifecycle("Finished "+ Integer.toString(count++) + " tests")
            }
        }
    } else {
        // show standard out and standard error of the test JVM(s) on the console
        testLogging.showStandardStreams = true
        beforeTest { descriptor ->
            logger.lifecycle("Running Test: " + descriptor)
        }

        // listen to standard out and standard error of the test JVM(s)
        onOutput { descriptor, event ->
            logger.lifecycle("Test: " + descriptor + " produced standard out/err: " + event.message )
        }
    }
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.12'
}

tasks.withType(ShadowJar) {
    manifest {
        attributes 'Implementation-Title': 'Hellbender',
                'Implementation-Version': version,
                'Main-Class': 'org.broadinstitute.hellbender.Main'
    }
    from(project.sourceSets.main.output)
    baseName = project.name + '-all'
    mergeServiceFiles()
    relocate 'com.google.common', 'org.broadinstitute.hellbender.relocated.com.google.common'
    zip64 true
    exclude 'log4j.properties' // from adam jar as it clashes with hellbender's log4j2.xml
}


configurations {
    sparkConfiguration {
        extendsFrom runtime
        // exclude Hadoop and Spark dependencies, since they are provided when running with Spark
        // (ref: http://unethicalblogger.com/2015/07/15/gradle-goodness-excluding-depends-from-shadow.html)
        exclude group: 'org.apache.hadoop'
        exclude module: 'spark-core_2.10'
        exclude group: 'org.slf4j'
    }
}

shadowJar {
    configurations = [project.configurations.runtime]
    classifier = 'shadowJar'
    mergeServiceFiles('reference.conf')
}

task sparkJar(type: ShadowJar) {
    group = "Shadow"
    description = "Create a combined jar of project and runtime dependencies that excludes provided spark dependencies"
    configurations = [project.configurations.sparkConfiguration]
    classifier = 'spark'
}

task javadocJar(type: Jar, dependsOn: javadoc) {
    classifier = 'javadoc'
    from 'build/docs/javadoc'
}

task sourcesJar(type: Jar) {
    from sourceSets.main.allSource
    classifier = 'sources'
}

// This is a hack to disable the java 8 default javadoc lint until we fix the html formatting
if (JavaVersion.current().isJava8Compatible()) {
    tasks.withType(Javadoc) {
        options.addStringOption('Xdoclint:none', '-quiet')
    }
}

/**
 *This specifies what artifacts will be built and uploaded when performing a maven upload.
 */
artifacts {
    archives jar
    archives javadocJar
    archives sourcesJar
}

/**
 * Sign non-snapshot releases with our secret key.  This should never need to be invoked directly.
 */
signing {
    required { isRelease && gradle.taskGraph.hasTask("uploadArchives") }
    sign configurations.archives
}

/**
 * Upload a release to sonatype.  You must be an authorized uploader and have your sonatype
 * username and password information in your gradle properties file.  See the readme for more info.
 *
 * For releasing to your local maven repo, use gradle install
 */
uploadArchives {
    if(project.hasProperty('sonatypeUsername') && project.hasProperty('sonatypePassword')){
        repositories {
            mavenDeployer {
                beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

                repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
                    authentication(userName: sonatypeUsername, password: sonatypePassword)
                }

                snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots") {
                    authentication(userName: sonatypeUsername, password: sonatypePassword)
                }

                pom.project {
                    name 'Hellbender'
                    packaging 'jar'
                    description 'Development on GATK4'
                    url 'http://github.com/broadinstitute/hellbender'

                    scm {
                        url 'scm:git@github.com:broadinstitute/hellbender.git'
                        connection 'scm:git@github.com:broadinstitute/hellbender.git'
                        developerConnection 'scm:git@github.com:broadinstitute/hellbender.git'
                    }

                    licenses {
                        license {
                            name 'BSD 3-Clause'
                            url 'https://github.com/broadinstitute/hellbender/blob/master/LICENSE.TXT'
                            distribution 'repo'
                        }
                    }
                }
            }
        }
    } else {
        doFirst({
            logger.error( 'Users are not generally supposed to upload archives.  ' +
                'To upload archives you must specify certain information in your gradle.properties. See the README' +
                ' for more information.' )
            throw new Exception("Missing sonatype username or password, please see the README for properties that must be specified for uploading an archive.")}
        )
    }


task installSpark{ dependsOn sparkJar }
task installAll{  dependsOn installSpark, installDist }

installDist.dependsOn downloadGsaLibFile, extractIntelDeflater
build.dependsOn installDist
check.dependsOn installDist

model {
    components {
        VectorLoglessPairHMM(NativeLibrarySpec) {
            // set location of source files
            sources.cpp.source {
                srcDirs "src/main/cpp/VectorLoglessPairHMM"
                include "*.cc"
            }

            binaries.withType(SharedLibraryBinarySpec) { binary ->
                if (System.env.GATK_SKIP_NATIVE_BUILD.toString().toBoolean()) {
                    buildable = false
                    println("INFO: \$GATK_SKIP_NATIVE_BUILD is true, skipping native AVX PairHMM library build.")
                } else if (!OperatingSystem.current().isLinux() && !OperatingSystem.current().isMacOsX()) {
                    buildable = false
                    println("WARNING: Building the native AVX PairHMM library is not supported on this OS.")
                } else {
                    cppCompiler.args "-I", "${System.properties['java.home']}/../include"
                    cppCompiler.args "-Wall"
		    if(System.getProperty("os.arch") == "ppc64le") {
                      cppCompiler.args "-mcpu=power8"
                      cppCompiler.args "-mtune=power8"
                      cppCompiler.args "-fopenmp"
                      linker.args "-lgomp"
		    } else {
                      cppCompiler.args "-mavx"
		    }

                    // build with gcov options on Travis
                    if (System.env.CI.toString().toBoolean()) {
                        cppCompiler.args "-g"
                        cppCompiler.args "-O0"
                        cppCompiler.args "--coverage"
                        linker.args "--coverage"
                    } else {
                        cppCompiler.args "-O3"
                    }

                    if (org.gradle.internal.os.OperatingSystem.current().isMacOsX()) {
                        cppCompiler.args "-I", "${System.properties['java.home']}/../include/Darwin"
                    } else {
                        cppCompiler.args "-I", "${System.properties['java.home']}/../include/linux"
                        linker.args "-static-libgcc"
                    }

                    task copySharedLib(type: Copy) {
                        from binary.sharedLibraryFile
                        into "$compileJava.destinationDir/lib"
                        dependsOn binary.tasks
                    }

                    jar.dependsOn copySharedLib
                    shadowJar.dependsOn copySharedLib
                    sparkJar.dependsOn copySharedLib
                    test.dependsOn copySharedLib
                }
            }

            // skip static library build
            binaries.withType(StaticLibraryBinarySpec) { binary ->
                buildable = false
            }
        }
    }

    toolChains {
        if (org.gradle.internal.os.OperatingSystem.current().isMacOsX()) {
            clang(Clang)
        } else {
            gcc(Gcc) {
	      target("linux_ppc64le")	// tentative fix until gradle supports linux ppc64le
	    }
        }
    }
    platforms {
        linux_ppc64le { 		// tentative fix until gradle supports linux ppc64le
	    architecture "ppc64le"
	}
    }
}

}
