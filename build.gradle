buildscript {
    repositories {
        mavenCentral()
        jcenter() // for shadow plugin
     }

    dependencies {
        classpath 'org.kt3k.gradle.plugin:coveralls-gradle-plugin:2.4.0'
        classpath 'com.github.jengelman.gradle.plugins:shadow:1.2.2'
        classpath 'com.github.ben-manes:gradle-versions-plugin:0.11.3'  //used for identifying dependencies that need updating
    }
}

plugins {
    id "de.undercouch.download" version "1.2"
}

import de.undercouch.gradle.tasks.download.Download

apply plugin: 'java'
apply plugin: 'idea'
apply plugin: 'application'
apply plugin: "jacoco"
apply plugin: 'com.github.kt3k.coveralls'
apply plugin: 'maven'
apply plugin: 'signing'
apply plugin: 'com.github.johnrengelman.shadow'
apply plugin: 'com.github.ben-manes.versions'

mainClassName = "org.broadinstitute.hellbender.Main"

task downloadGsaLibFile(type: Download) {
    src 'http://cran.r-project.org/src/contrib/gsalib_2.1.tar.gz'
    dest "src/main/resources/org/broadinstitute/hellbender/utils/R/gsalib.tar.gz"
    overwrite false
}


repositories {
    mavenCentral()
    jcenter()
    maven {
        url "https://repository.cloudera.com/artifactory/cloudera-repos/" // spark-dataflow
    }
    maven {
        url "https://oss.sonatype.org/content/repositories/snapshots/"
    }
}

configurations.all {
    resolutionStrategy {
        force 'com.google.http-client:google-http-client:1.21.0-SNAPSHOT'
    }
}

jacocoTestReport {
    dependsOn test
    group = "Reporting"
    description = "Generate Jacoco coverage reports after running tests."
    additionalSourceDirs = files(sourceSets.main.allJava.srcDirs)

    reports {
        xml.enabled = true // coveralls plugin depends on xml format report
        html.enabled = true
    }
}

jacoco {
    toolVersion = "0.7.1.201405082137"
}

//NOTE: we ignore contracts for now
compileJava {
  options.compilerArgs = ['-proc:none', '-Xlint:all','-Werror']
}
compileTestJava { 
  options.compilerArgs = ['-proc:none', '-Xlint:all','-Werror']
}

installApp.dependsOn downloadGsaLibFile
build.dependsOn installApp
check.dependsOn installApp

dependencies {
    compile files("${System.properties['java.home']}/../lib/tools.jar")

    compile 'com.github.samtools:htsjdk:1.138'
    compile ('com.google.cloud.genomics:google-genomics-dataflow:v1beta2-0.14') {
        // an upstream dependency includes guava-jdk5, but we want the newer version instead.
        exclude module: 'guava-jdk5'
    }
    compile ('com.google.cloud.genomics:gatk-tools-java:1.1') {
        exclude module: 'guava-jdk5'
    }
    compile 'org.apache.logging.log4j:log4j-api:2.3'
    compile 'org.apache.logging.log4j:log4j-core:2.3'
    compile 'org.apache.commons:commons-lang3:3.4'
    compile 'org.apache.commons:commons-math3:3.5'
    compile 'org.apache.commons:commons-collections4:4.0'
    compile 'org.apache.commons:commons-vfs2:2.0'
    compile 'commons-io:commons-io:2.4'
    compile 'org.reflections:reflections:0.9.10'
    compile 'net.sf.jopt-simple:jopt-simple:4.9'
    compile 'com.google.cloud.dataflow:google-cloud-dataflow-java-sdk-all:0.4.150727'
    compile ('com.google.apis:google-api-services-genomics:v1beta2-rev56-1.20.0') {
        exclude module: 'guava-jdk5'
    }
    compile ('com.google.cloud.genomics:google-genomics-utils:v1beta2-0.30') {
        exclude module: 'guava-jdk5'
    }
    compile 'com.google.guava:guava:18.0'
    compile 'com.google.appengine.tools:appengine-gcs-client:0.4.4'
    compile 'org.jgrapht:jgrapht-core:0.9.1'
    compile 'org.testng:testng:6.9.6' //compile instead of testCompile because it is needed for test infrastructure that needs to be packaged
    compile 'com.cloudera.dataflow.spark:spark-dataflow:0.4.0'
    compile('org.seqdoop:hadoop-bam:7.1.0') {
        exclude group: 'org.apache.hadoop'
        exclude module: 'htsjdk'
    }
    compile('org.apache.hadoop:hadoop-client:2.7.1')

    //needed for DataflowAssert
    testCompile 'org.hamcrest:hamcrest-all:1.3'
    testCompile 'junit:junit:4.12'
    testCompile 'org.apache.hadoop:hadoop-minicluster:2.7.1'
    testCompile "org.mockito:mockito-core:1.10.19"
    testCompile('org.apache.spark:spark-core_2.10:1.4.1') {
        // JUL is used by Google Dataflow as the backend logger, so exclude jul-to-slf4j to avoid a loop
        exclude module: 'jul-to-slf4j'
        exclude module: 'javax.servlet'
        exclude module: 'servlet-api'
    }

}

sourceCompatibility = 1.8
targetCompatibility = 1.8

def String deriveVersion(){
    def stdout = new ByteArrayOutputStream()
    try {
        logger.info("path is $System.env.PATH")
        exec {
            commandLine "git", "describe", "--always"
            standardOutput = stdout;

            ignoreExitValue = true
        }
    } catch (GradleException e) {
        logger.error("Couldn't determine version.  " + e.getMessage())
    }
    return stdout.size() > 0 ? stdout.toString().trim() : "version-unknown"
}
final SNAPSHOT = "-SNAPSHOT"
version = deriveVersion() + SNAPSHOT  //all builds are snapshot builds until we decide that there is something we want to keep
boolean isRelease = ! version.endsWith(SNAPSHOT)
logger.info("build for version:" + version)
group = 'org.broadinstitute'


jar {
    manifest {
        attributes 'Implementation-Title': 'Hellbender-tools',
                'Implementation-Version': version,
                'Main-Class': 'org.broadinstitute.hellbender.Main'
    }
}


task testAll(type: Test){
    useTestNG{}

    // ensure dataflowRunner is passed to the test VM if specified on the command line
    systemProperty "dataflowRunner", System.getProperty("dataflowRunner")
    // increase max buffer size for Spark serialization
    systemProperty "spark.kryoserializer.buffer.max", "256m"

    // set heap size for the test JVM(s)
    minHeapSize = "1G"
    maxHeapSize = "2G"

    // show standard out and standard error of the test JVM(s) on the console
    testLogging.showStandardStreams = true
    beforeTest { descriptor ->
        logger.lifecycle("Running Test: " + descriptor)
    }

    // listen to standard out and standard error of the test JVM(s)
    onOutput { descriptor, event ->
        logger.lifecycle("Test: " + descriptor + " produced standard out/err: " + event.message )
    }
}

test {
    String CI = "$System.env.CI"
    useTestNG{
        if ( "$System.env.CLOUD" =="true"){
            includeGroups 'cloud', 'bucket'
        } else {
            excludeGroups 'cloud', 'bucket'
        }
    }

    // ensure dataflowRunner is passed to the test VM if specified on the command line
    systemProperty "dataflowRunner", System.getProperty("dataflowRunner")
    // increase max buffer size for Spark serialization
    systemProperty "spark.kryoserializer.buffer.max", "256m"

    // set heap size for the test JVM(s)
    minHeapSize = "1G"
    maxHeapSize = "2G"

    if (CI == "true") {
        int count = 0
        // listen to events in the test execution lifecycle
        testLogging {
            events "skipped", "failed"
            exceptionFormat = "full"
        }

        beforeTest { descriptor ->
            count++
            if( count % 10000 == 0) {
                logger.lifecycle("Finished "+ Integer.toString(count++) + " tests")
            }
        }
    } else {
        // show standard out and standard error of the test JVM(s) on the console
        testLogging.showStandardStreams = true
        beforeTest { descriptor ->
            logger.lifecycle("Running Test: " + descriptor)
        }

        // listen to standard out and standard error of the test JVM(s)
        onOutput { descriptor, event ->
            logger.lifecycle("Test: " + descriptor + " produced standard out/err: " + event.message )
        }
    }
}

task wrapper(type: Wrapper) {
    gradleVersion = '2.2.1'
}


task fatJar(type: Jar) {
  manifest {
        attributes 'Implementation-Title': 'Hellbender',
          'Implementation-Version': version,
          'Main-Class': 'org.broadinstitute.hellbender.Main'
    }
    baseName = project.name + '-all'
    from { configurations.compile.collect { it.isDirectory() ? it : zipTree(it) } }
    with jar
}

shadowJar {
    manifest {
        attributes 'Implementation-Title': 'Hellbender',
                'Implementation-Version': version,
                'Main-Class': 'org.broadinstitute.hellbender.Main'
    }
    baseName = project.name + '-all'
    classifier = 'spark'
    mergeServiceFiles()
    relocate 'com.google.common', 'org.broadinstitute.hellbender.relocated.com.google.common'
    zip64 true
    dependencies {
        // exclude Hadoop dependencies, since they are provided when running with Spark
        exclude(dependency('org.apache.hadoop:.*:.*'))
        exclude(dependency('org.xerial.snappy:snappy-java:.*'))
    }
}

task javadocJar(type: Jar, dependsOn: javadoc) {
    classifier = 'javadoc'
    from 'build/docs/javadoc'
}

task sourcesJar(type: Jar) {
    from sourceSets.main.allSource
    classifier = 'sources'
}

// This is a hack to disable the java 8 default javadoc lint until we fix the html formatting
if (JavaVersion.current().isJava8Compatible()) {
    tasks.withType(Javadoc) {
        options.addStringOption('Xdoclint:none', '-quiet')
    }
}

/**
 *This specifies what artifacts will be built and uploaded when performing a maven upload.
 */
artifacts {
    archives jar
    archives javadocJar
    archives sourcesJar
}

/**
 * Sign non-snapshot releases with our secret key.  This should never need to be invoked directly.
 */
signing {
    required { isRelease && gradle.taskGraph.hasTask("uploadArchives") }
    sign configurations.archives
}

/**
 * Upload a release to sonatype.  You must be an authorized uploader and have your sonatype
 * username and password information in your gradle properties file.  See the readme for more info.
 *
 * For releasing to your local maven repo, use gradle install
 */
uploadArchives {
    if(project.hasProperty('sonatypeUsername') && project.hasProperty('sonatypePassword')){
        repositories {
            mavenDeployer {
                beforeDeployment { MavenDeployment deployment -> signing.signPom(deployment) }

                repository(url: "https://oss.sonatype.org/service/local/staging/deploy/maven2/") {
                    authentication(userName: sonatypeUsername, password: sonatypePassword)
                }

                snapshotRepository(url: "https://oss.sonatype.org/content/repositories/snapshots") {
                    authentication(userName: sonatypeUsername, password: sonatypePassword)
                }

                pom.project {
                    name 'Hellbender'
                    packaging 'jar'
                    description 'Development on GATK4'
                    url 'http://github.com/broadinstitute/hellbender'

                    scm {
                        url 'scm:git@github.com:broadinstitute/hellbender.git'
                        connection 'scm:git@github.com:broadinstitute/hellbender.git'
                        developerConnection 'scm:git@github.com:broadinstitute/hellbender.git'
                    }

                    licenses {
                        license {
                            name 'BSD 3-Clause'
                            url 'https://github.com/broadinstitute/hellbender/blob/master/LICENSE.TXT'
                            distribution 'repo'
                        }
                    }
                }
            }
        }
    } else {
        doFirst({
            logger.error( 'Users are not generally supposed to upload archives.  ' +
                'To upload archives you must specify certain information in your gradle.properties. See the README' +
                ' for more information.' )
            throw new Exception("Missing sonatype username or password, please see the README for properties that must be specified for uploading an archive.")}
        )

    }
}
