# Generating Callset Precision and Sensitivity Values

## Prerequisites
1. Complete (at least) through the training step (`GvsCreateFilterSet`) of the [GVS pipeline](../docs/aou/AOU_DELIVERABLES.md) with all the samples (control and non-control).
1. Run the `GvsPrepareRanges` WDL with the following input values:
   1. `call_set_identifier`, `dataset_name`, `project_id` set to the same values as the inputs of the same name in the preceding `GvsCreateFilterSet` run.
   1. `control_samples` set to `true`.
   1. Make sure to set `use_compressed_references` to the appropriate value. This will be `true` for AoU callsets starting with Echo.
1. Run the `GvsExtractCallset` WDL with the following input values:
   1. `call_set_identifier`, `dataset_name`, `filter_set_name`, `project_id` set to the same values as the inputs of the same name in the preceding `GvsCreateFilterSet` run.
   1. `extract_table_prefix` set to the same value as `call_set_identifier`.
   1. `control_samples` set to `true`.
   1. `scatter_count` set to 500. This is an optional input value but at least for the Echo scale test control extract prior to P+S, leaving this unset causes most of the 111 `ExtractTask` shards to OOM.

## Precision and Sensitivity
1. Use the GvsCalculatePrecisionAndSensitivity wdl to calculate the precision and sensitivity.
   1. You will need to have "Storage Object View" access granted for your @pmi-ops proxy group on the `gs://broad-dsp-spec-ops/gvs/truth` directory
   1. This workflow does not use the Terra Data Entity Model to run, so be sure to select the `Run workflow with inputs defined by file paths` workflow submission option.


The wdl takes several inputs as described below. Pro tip: it can be useful to look at the inputs from prior successful
runs of the precision and sensitivity workflow *as a model* for new runs, being careful to update values as necessary.
The inputs `sample_names`, `truth_vcfs`, `truth_vcf_indexes`, `truth_beds`, and `truth_fasta` are parallel arrays that
should all be updated in lockstep with one another. `input_vcf_fofn` will need to be generated anew for every unique upstream
run of `GvsExtractCallset`, while `chromosome` and `ref_fasta` will likely remain the same for every run.


**input_vcf_fofn** - A FOFN (file of file names) of output VCFs for control samples generated by `GvsExtractCallSet`. These need not be subsetted down to the chromosome.
The FOFN should contain the full cloud paths to the VCFs, not just the file names.

The `GvsExtractCallset` workflow should have an output of type `Array[File]` called `output_vcfs`. If one of the vcfs in this array has a path like:

```
gs://<long prefix with workspace id, submission id, etc>/call-ExtractTask/shard-0/control-001-extract.vcf.gz
```

Then all the output control VCFs might be selected into a FOFN with some globbing. Perform the following in a notebook
in the workspace:

```
gsutil ls 'gs://<long prefix with workspace id, submission id, etc>/call-ExtractTask/shard-*/*.vcf.gz' > vcfs_fofn.txt

gsutil cp vcfs_fofn.txt <workspace_bucket>/p_and_s/vcfs_fofn.txt
```

**output_basename** - The base name for the output files generated by the pipeline.

**chromosome** - The chromosome on which to run the analysis of Precision and Sensitivity. The default value for this is `chr20`. If it is set to `all` then the analysis will be run across *all* chromosomes.

**sample_names** - A list of the sample names that are controls and that will be used for the analysis. For every element on the list of sample names there must be a corresponding element on the list of `truth_vcfs`, `truth_vcf_indices`, and `truth_beds`.

```
[ "NA12878", \
  "NA24385"
```
**truth_vcfs** - A list of the VCFs that contain the truth data used for analyzing the samples in `sample_names`.

```
[ "gs://broad-gotc-test-storage/gvs/truth/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz", \
  "gs://broad-gotc-test-storage/gvs/truth/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz"
```
**truth_vcf_indices** - A list of the VCF indices for the truth data VCFs supplied above.

```
[ "gs://broad-gotc-test-storage/gvs/truth/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz.tbi", \
  "gs://broad-gotc-test-storage/gvs/truth/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz.tbi"
```

**truth_beds** - A list of the bed files for the truth data used for analyzing the samples in `sample_names`.

```
[ "gs://broad-gotc-test-storage/gvs/truth/HG001.gvs.evaluation.bed", \
  "gs://broad-gotc-test-storage/gvs/truth/HG002.gvs.evaluation.bed"
```

**ref_fasta** - The cloud path for the reference fasta sequence.


## Appendix A: View ROCs
To view ROC curves for the data you will need to set up rtg-tools locally, using the following steps (typically you need do this only once):

1. Use `conda` to create a fresh environment to add these new tools to it:
 ```
 conda create --name gvs python=3.8
 conda activate gvs
 conda install -c bioconda rtg-tools
```
The base files needed to generate the ROC curves are among the outputs of the `GvsCalculatePrecisionAndSensitivity` wdl

You can use wildcards to pull in multiple datasets into the graphical viewer. For example
```
rtg roc NA12878_*_roc*/snp_roc.tsv.gz 
rtg roc NA12878_*_roc*/indel_roc.tsv.gz 
```
## Appendix B: Control Samples

"Truth" versions of control samples for this analysis are stored in:
```
gs://broad-dsp-spec-ops/gvs/truth/*
```

If you are missing any follow these steps there to add and prepare them to the above location

"Truth" versions of control samples are from the [Genome in a Bottle Consortium (GIAB)](https://www.nist.gov/programs-projects/genome-bottle) and [releases of their data can be found here](https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/) organized by source.
1. Download the `.bed`, `.vcf` and index files associated with the control sample.
2. Convert the calling region GVS is using to BED format
```
gsutil cp gs://gcp-public-data--broad-references/hg38/v0/wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list .
gatk IntervalListToBed -I wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list -O wgs_calling_regions.hg38.noCentromeres.noTelomeres.bed
rm wgs_calling_regions.hg38.noCentromeres.noTelomeres.interval_list
```
3. Then intersect with each of the truth datasets (this example is for HG-001):
```
bedtools intersect -a wgs_calling_regions.hg38.noCentromeres.noTelomeres.bed -b HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_nosomaticdel_noCENorHET7.bed > HG001.gvs.evaluation.bed
bedtools intersect -a wgs_calling_regions.hg38.noCentromeres.noTelomeres.bed -b HG002_GRCh38_1_22_v4.2.1_benchmark_noinconsistent.bed > HG002.gvs.evaluation.bed
bedtools intersect -a wgs_calling_regions.hg38.noCentromeres.noTelomeres.bed -b HG003_GRCh38_1_22_v4.2.1_benchmark_noinconsistent.bed > HG003.gvs.evaluation.bed
bedtools intersect -a wgs_calling_regions.hg38.noCentromeres.noTelomeres.bed -b CHM.full.38.bed.gz > CHM.gvs.evaluation.bed
```
4. Copy the GIAB data and the new `evaluation.bed` file to the `gs://broad-dsp-spec-ops/gvs/truth/` directory so the files will be available for future callsets.
