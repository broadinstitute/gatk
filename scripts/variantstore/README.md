
# Getting started with GvsJointVariantCalling.wdl - Joint Calling with the Broad Genomic Variant Store

**Note:** The markdown source for this quickstart is maintained in the the  [GATK GitHub Repository](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/README.md). Submit any feedback, corrections or improvements in a pull request there.  Do not edit this file directly.


## Overview
With this pipeline you will use the Broad Genomic Variant Store to create a GATK VQSR Filtered joint callset VCF.

The GvsJointVariantCalling WDL is a wrapper WDL that expedites the creation of a callset using the GVS pipeline.
* It is a wrapper for the common GVS pipeline.
* It sets many params to common defaults.
* It is meant as a simple way of running a complex process, so it is straightforward to run and inflexible.


## Prerequisites
This quickstart assumes that you are familiar with Terra workspaces, the data model and providing input parameters and launching workflows.

1. You will need to have or create a Google **project**  (this corresponds to the input param: `project_id`).
2. You will need to put the gVCFs you are using into a GCP bucket
3. You will need to have or create a BigQuery **dataset** (this corresponds to the input param: `dataset_name`).
4. Grant the "BigQuery Data Editor" role on that **dataset** to your Terra PROXY group.  Your proxy group name can be found on your Terra Profile page and look something like `PROXY_12345678901234567890@firecloud.org`.
5. Grant the following roles on the **project** containing the dataset to your proxy group:
    - BigQuery data editor
    - BigQuery job user
    - BigQuery Read Session User
6. These tools expect re-blocked gVCF files as input. Instructions on how to re-block gVCFs are below.
7. You will need to have or create a [Terra account](https://app.terra.bio/)


## Prepare your workspace 
* Clone the Terra workspace [Genomic\_Variant\_Store\_beta\_dev\_version](https://app.terra.bio/#workspaces/help-terra/Genomic%20Variant%20Store%20beta%20dev%20version)
* Load your data into the Terra workspace (Link to documentation for Terra data loading)
* Create a sample set from the Data table by selecting all desired samples, clicking the pencil icon (edit), and choosing "Save Selection as Set" (the docs will refer to this set as: `gvs_sample_set`).
* Share your Terra the workspace with the variants team at Broad (variants@broadinstitute.org)
* Note that the GvsJointVariantCalling workflow will already be in your cloned workspace (https://support.terra.bio/hc/en-us/articles/360036379771-Get-started-running-workflows)

Once the data is loaded into your workspace, let us know by emailing Kylee and one of our engineers will validate your data


## Run the pipeline
Now that the samples have been validated and made into a sample set, run the GvsJointVariantCalling.wdl against this sample set.
Do this by selecting "sample_set" as the root entity type ("Step 1" on the workflow submission page) and `gvs_sample_set` for the data ("Step 2" on the workflow submission page).  
Since you are creating your own sample set, note that the sample table should have columns for the re-blocked gVCFs (`hg38_reblocked_gvcf` or `reblocked_gvcf_path`) and their index files.


These are the required parameters which must be supplied to the workflow:

| Parameter             | Description                                                                                    |
|-----------------------|------------------------------------------------------------------------------------------------|
| dataset_name          | the name of the dataset you created above                                                      |
| project_id            | the name of the google project containing the dataset                                          |
| external_sample_names | `this.samples.sample_id` (the sample identifier column from the `gvs_sample_set` sample set)   |
| input_vcfs            | the name of the google project containing the dataset                                          |
| input_vcf_indexes     | the index files for the above gVCFs                                                            |
| callset_identifier    | the desired name for the exported callset                                                      |



## Your VCF files are ready!
The sharded VCF output files are listed in the `Unified.output_vcf` workflow output, and the associated index files are listed in `Unified.output_vcf_index`.



## Reblocking your samples 
(this is a prerequisite and only necessary if your samples have not been reblocked)

#### y'all, why is the only reblocking WDL I see for our use case seemingly an AoU specific one?!?!??!

Sometimes the reblocking will fail for a small number of samples, so not all of the samples in the sample set with have the attribute "reblocked\_gvcf\_path". This wdl works on a sample set which means it is passed arrays of attributes all of which need to be filled in. 
We need to create a sample set for loading with the subset of samples that have reblocked gvcfs. 