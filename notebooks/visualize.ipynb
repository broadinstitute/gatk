{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# ml4h Imports\n",
    "from ml4h.arguments import parse_args\n",
    "from ml4h.models import make_multimodal_multitask_model, train_model_from_generators\n",
    "\n",
    "# IPython imports\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_channel(args, model, layer_dict, layer_name='conv5_1', channel=0):\n",
    "\tK.set_learning_phase(1)\n",
    "\tinput_tensor = model.input\n",
    "\tif K.image_data_format()== 'channels_first':\n",
    "\t\tx = layer_dict[layer_name].output[:,channel,:,:]\n",
    "\telse:\n",
    "\t\tx = layer_dict[layer_name].output[:,:,:,channel]\n",
    "\t\n",
    "\tw = x.shape[1]\n",
    "\th = x.shape[2]\n",
    "\tshape = layer_dict[layer_name].output_shape\n",
    "\n",
    "\tobjective = K.variable(0.)\n",
    "\n",
    "\tobjective += K.sum(K.square(x[:, 2: w-2, 2:h-2])) / np.prod(shape[1:])\n",
    "\n",
    "\t# add continuity loss (gives image local coherence, can result in an artful blur)\n",
    "\t#objective -= args.total_variation * total_variation_norm(input_tensor) / np.prod(x.shape[1:])\n",
    "\t# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n",
    "\t#objective -= args.l2 * K.sum(K.square(input_tensor)) / np.prod(x.shape[1:])\n",
    "\t\n",
    "\t# compute the gradient of the input picture wrt this loss\n",
    "\tgrads = K.gradients(objective, input_tensor)[0]\n",
    "\n",
    "\t# normalization trick: we normalize the gradient\n",
    "\tgrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-6)\n",
    "\n",
    "\t# this function returns the loss and grads given the input picture\n",
    "\titerate = K.function([input_tensor], [objective, grads])\n",
    "\treturn iterate\n",
    "\n",
    "def iterate_channel_1d(args, model, layer_dict, layer_name='conv5_1', channel=0):\n",
    "\tK.set_learning_phase(1)\n",
    "\tinput_tensor = model.input\n",
    "\tif K.image_data_format()== 'channels_first':\n",
    "\t\tx = layer_dict[layer_name].output[:,channel,:]\n",
    "\telse:\n",
    "\t\tx = layer_dict[layer_name].output[:,:,channel]\n",
    "\t\n",
    "\tw = x.shape[1]\n",
    "\tshape = layer_dict[layer_name].output_shape\n",
    "\n",
    "\tobjective = K.variable(0.)\n",
    "\n",
    "\tobjective += K.sum(K.square(x[:, 2: w-2])) / np.prod(shape[1:])\n",
    "\n",
    "\t# add continuity loss (gives image local coherence, can result in an artful blur)\n",
    "\t#objective -= args.total_variation * total_variation_norm(input_tensor) / np.prod(x.shape[1:])\n",
    "\t# add image L2 norm to loss (prevents pixels from taking very high values, makes image darker)\n",
    "\t#objective -= args.l2 * K.sum(K.square(input_tensor)) / np.prod(x.shape[1:])\n",
    "\t\n",
    "\t# compute the gradient of the input picture wrt this loss\n",
    "\tgrads = K.gradients(objective, input_tensor)[0]\n",
    "\n",
    "\t# normalization trick: we normalize the gradient\n",
    "\tgrads /= (K.sqrt(K.mean(K.square(grads))) + 1e-6)\n",
    "\n",
    "\t# this function returns the loss and grads given the input picture\n",
    "\titerate = K.function([input_tensor], [objective, grads])\n",
    "\treturn iterate\n",
    "\n",
    "\n",
    "def write_filters(args, model, input_shape, iterate_fxn):\n",
    "\tjitter = 0.000001\n",
    "\tlayer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "\tfor layer in model.layers:\n",
    "\t\tfor filter_index in range(0, layer.output_shape[-1], 8):\n",
    "\t\t\tif not 'conv' in layer.name:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\titerate = iterate_fxn(args, model, layer_dict, layer.name, filter_index)\n",
    "\t\t\t#print(\"Layer name:\", layer.name, \"filter index:\", filter_index)\n",
    "\t\t\tinput_img_data = np.random.random(input_shape)\n",
    "\t\t\tout_file = os.path.join(args.output_folder, args.id, 'write_filters', '%s_filter_%d.png' % (layer.name, filter_index))\n",
    "\n",
    "\t\t\t# run gradient ascent\n",
    "\t\t\tfor i in range(args.epochs):\n",
    "\t\t\t\trandom_jitter = jitter * (np.random.random(input_shape) - 0.5)\n",
    "\t\t\t\tinput_img_data += random_jitter\n",
    "\t\t\t\tloss_value, grads_value = iterate([input_img_data])\n",
    "\t\t\t\tinput_img_data -= random_jitter\n",
    "\n",
    "\t\t\t\tinput_img_data += args.learning_rate*grads_value\n",
    "\t\t\t\t#if i % (args.epochs//164) == 0:\n",
    "\t\t\t\t#\tprint(\"  After iteration:\", i, \"loss is:\", loss_value,\" layer name:\", layer.name, \"filter index:\", filter_index)\n",
    "\t\t\t\n",
    "\t\t\tif not os.path.exists(os.path.dirname(out_file)):\n",
    "\t\t\t\tos.makedirs(os.path.dirname(out_file))\n",
    "\t\t\tprint('Saved:', out_file)\n",
    "\t\t\tif len(input_shape) == 4:\n",
    "\t\t\t\tplt.imsave(out_file, input_img_data[0,:,:,0])\n",
    "\t\t\tif len(input_shape) == 3:\n",
    "\t\t\t\trow = 0\n",
    "\t\t\t\tcol = 0\n",
    "\t\t\t\ttotal_plots = input_shape[-1]\n",
    "\t\t\t\trows = max(2, int(math.sqrt(total_plots)))\n",
    "\t\t\t\tcols = max(2, total_plots // rows)\n",
    "\t\t\t\tfig, axes = plt.subplots(rows, cols, figsize=(48, 48))\n",
    "\t\t\t\tfor i in range(total_plots):\n",
    "\t\t\t\t\taxes[row, col].plot(input_img_data[0,:,0])\n",
    "\t\t\t\t\trow += 1\n",
    "\t\t\t\t\tif row == rows:\n",
    "\t\t\t\t\t\trow = 0\n",
    "\t\t\t\t\t\tcol += 1\n",
    "\t\t\t\t\t\tif col >= cols:\n",
    "\t\t\t\t\t\t\tbreak            \n",
    "\t\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients_from_output(args, model, output_layer, output_index):\n",
    "    input_tensor = model.input\n",
    "    x = model.get_layer(output_layer).output[:,output_index]\n",
    "\n",
    "    objective = K.variable(0.)\n",
    "    objective += K.sum(K.square(x))\n",
    "\n",
    "    # compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(objective, input_tensor)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-6)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_tensor], [objective, grads])\n",
    "    return iterate\n",
    "\n",
    "\n",
    "def saliency_map(input_tensor, model, output_layer, output_index):\n",
    "    get_gradients = gradients_from_output(args, model, output_layer, output_index)\n",
    "    activation, grads = get_gradients([input_tensor])\n",
    "    print('Activation is:', activation, 'gradient shape:', grads.shape)\n",
    "    if len(input_tensor.shape) == 4:\n",
    "        plt.imshow(grads)\n",
    "    elif len(input_tensor.shape) == 3:\n",
    "        plt.plot(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/data/generated/tensors/test/2019-03-21/',\n",
    "            '--input_tensors', 'mri_slice_weighted', \n",
    "            '--output_tensors','mri_slice_segmented_weighted',\n",
    "            '--epochs', '260',\n",
    "            '--learning_rate', '0.1',\n",
    "            '--u_connect',\n",
    "            '--model_layers', '/mnt/ml4cvd/projects/jamesp/data/models/mri_slice_seg_unet.hd5',\n",
    "            '--id', 'mri_slice_segmenter']\n",
    "args = parse_args()\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, args.x, args.y,1) \n",
    "write_filters(args, model, input_shape, iterate_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_1_filter_16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_4_filter_8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_6_filter_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_8_filter_8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_12_filter_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_11_filter_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_7_filter_16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/mri_slice_segmenter/write_filters/conv2d_14_filter_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['train', \n",
    "            '--tensors', '/mnt/disks/ecg-text3/2019-04-26/',\n",
    "            '--input_tensors', 'ecg_rest_1lead', \n",
    "            '--output_tensors', 'ecg_median_1lead', 'ecg_normal', 'ecg_rhythm', 'p-axis', 'p-duration', 'p-offset', 'p-onset', 'pp-interval', 'pq-interval', 'q-offset', 'q-onset', 'qrs-duration', 'qrs-num', 'qt-interval', 'qtc-interval', 'ventricular-rate',\n",
    "            '--epochs', '260',\n",
    "            '--learning_rate', '0.1',\n",
    "            '--u_connect',\n",
    "            '--model_layers', '/mnt/ml4cvd/projects/jamesp/data/models/ecg_rest_wave_regress_afib_1lead.hd5',\n",
    "            '--id', 'ecg_rest_wave_regress_afib_1lead']\n",
    "args = parse_args()\n",
    "model = make_multimodal_multitask_model(**args.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = np.random.random((1,600,8))\n",
    "[print(layer.name) for layer in model.layers]\n",
    "saliency_map(input_tensor, model, 'output_ecg_rhythm_categorical', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = model.get_layer('conv1d_1')\n",
    "# w1 = d1.get_weights()\n",
    "# rows = max(2, w1[0].shape[-2])\n",
    "# cols = max(2, w1[0].shape[-1])\n",
    "# f, axes = plt.subplots(rows, cols, sharex=True, figsize=(int(rows * 12.5), int(cols * 2.5)))\n",
    "# for row in range(rows):\n",
    "#     for col in range(cols):\n",
    "#         axes[row, col].plot(w1[0][:,row, col])\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (1, 600, 8) \n",
    "write_filters(args, model, input_shape, iterate_channel_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('./recipes_output/ecg_rest_wave_regress_afib_1lead/write_filters/conv1d_8_filter_16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
